{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d39f9ea7-7080-40ac-a028-41b95ef1404e",
   "metadata": {},
   "source": [
    "# Package Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b30febe4-4b21-4b5f-ba00-3015e80fc28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io          import fits\n",
    "from astropy             import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from lib import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bec19841-db4e-402e-8aa4-30d18c588aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator-1\\Desktop\\New folder (6)\\DeepSpectra\n",
      "C:\\Users\\Administrator-1\\Desktop\\New folder (6)\\DeepSpectra\\data\\saury2014\\cubes\n",
      "C:\\Users\\Administrator-1\\Desktop\\New folder (6)\\DeepSpectra\\data\\saury2014\\fcnm\n",
      "C:\\Users\\Administrator-1\\Desktop\\New folder (6)\\DeepSpectra\\data\\saury2014\\RHI\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "import sys, os\n",
    "base_path = os.getcwd()\n",
    "data_path  = os.path.join(base_path, 'data')\n",
    "data_cube_path = os.path.join(data_path, 'saury2014','cubes')\n",
    "fcnm_path = os.path.join(data_path, 'saury2014','fcnm')\n",
    "rhi_path = os.path.join(data_path, 'saury2014','RHI')\n",
    "print(data_cube_path)\n",
    "print(fcnm_path)\n",
    "print(rhi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81a74be3-403e-4d62-9636-edfe84359fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator-1\\Desktop\\New folder (6)\\DeepSpectra\\data\\saury2014\\cubes\\Tb_n01_pw02_vs12_512_thick_quarter_0_noise_1.0_K_beam_1.45_pix_.fits\n",
      "C:\\Users\\Administrator-1\\Desktop\\New folder (6)\\DeepSpectra\\data\\saury2014\\fcnm\\fcnm_map_n01_pw02_vs12_Tcut_500K_512px_quarter_0_noise.fits\n",
      "C:\\Users\\Administrator-1\\Desktop\\New folder (6)\\DeepSpectra\\data\\saury2014\\RHI\\R_map_n01_pw02_vs12_512px_quarter_0_noise.fits\n"
     ]
    }
   ],
   "source": [
    "# Training and test datasets\n",
    "# 1. Datacubes: 04 datacubes with size of (512 x 512 x 101)\n",
    "training_data_file_q0 = 'Tb_n01_pw02_vs12_512_thick_quarter_0_noise_1.0_K_beam_1.45_pix_.fits'\n",
    "training_data_file_q1 = 'Tb_n01_pw02_vs12_512_thick_quarter_1_noise_1.0_K_beam_1.45_pix_.fits'\n",
    "training_data_file_q2 = 'Tb_n01_pw02_vs12_512_thick_quarter_2_noise_1.0_K_beam_1.45_pix_.fits'\n",
    "training_data_file_q3 = 'Tb_n01_pw02_vs12_512_thick_quarter_3_noise_1.0_K_beam_1.45_pix_.fits'\n",
    "\n",
    "training_data_file_q0 = os.path.join(data_cube_path, training_data_file_q0)\n",
    "training_data_file_q1 = os.path.join(data_cube_path, training_data_file_q1)\n",
    "training_data_file_q2 = os.path.join(data_cube_path, training_data_file_q2)\n",
    "training_data_file_q3 = os.path.join(data_cube_path, training_data_file_q3)\n",
    "\n",
    "# 2a. R_HI maps\n",
    "rhi_file_q0 = 'R_map_n01_pw02_vs12_512px_quarter_0_noise.fits'\n",
    "rhi_file_q1 = 'R_map_n01_pw02_vs12_512px_quarter_1_noise.fits'\n",
    "rhi_file_q2 = 'R_map_n01_pw02_vs12_512px_quarter_2_noise.fits'\n",
    "rhi_file_q3 = 'R_map_n01_pw02_vs12_512px_quarter_3_noise.fits'\n",
    "\n",
    "rhi_file_q0 = os.path.join(rhi_path, rhi_file_q0)\n",
    "rhi_file_q1 = os.path.join(rhi_path, rhi_file_q1)\n",
    "rhi_file_q2 = os.path.join(rhi_path, rhi_file_q2)\n",
    "rhi_file_q3 = os.path.join(rhi_path, rhi_file_q3)\n",
    "\n",
    "# 3a. FCNM maps with noise\n",
    "fcnm_file_q0 = 'fcnm_map_n01_pw02_vs12_Tcut_500K_512px_quarter_0_noise.fits'\n",
    "fcnm_file_q1 = 'fcnm_map_n01_pw02_vs12_Tcut_500K_512px_quarter_1_noise.fits'\n",
    "fcnm_file_q2 = 'fcnm_map_n01_pw02_vs12_Tcut_500K_512px_quarter_2_noise.fits'\n",
    "fcnm_file_q3 = 'fcnm_map_n01_pw02_vs12_Tcut_500K_512px_quarter_3_noise.fits'\n",
    "\n",
    "fcnm_file_q0 = os.path.join(fcnm_path, fcnm_file_q0)\n",
    "fcnm_file_q1 = os.path.join(fcnm_path, fcnm_file_q1)\n",
    "fcnm_file_q2 = os.path.join(fcnm_path, fcnm_file_q2)\n",
    "fcnm_file_q3 = os.path.join(fcnm_path, fcnm_file_q3)\n",
    "\n",
    "print(training_data_file_q0)\n",
    "print(fcnm_file_q0)\n",
    "print(rhi_file_q0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6727ddb3-7cab-46b1-a1b1-2930158d3ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cube1, header1 = fits.getdata(training_data_file_q0, header=True)\n",
    "cube2, header2 = fits.getdata(training_data_file_q1, header=True)\n",
    "cube3, header3 = fits.getdata(training_data_file_q2, header=True)\n",
    "cube4, header4 = fits.getdata(training_data_file_q3, header=True)\n",
    "#\n",
    "fcnm_data1, header1 = fits.getdata(fcnm_file_q0, header=True)\n",
    "fcnm_data2, header2 = fits.getdata(fcnm_file_q1, header=True)\n",
    "fcnm_data3, header3 = fits.getdata(fcnm_file_q2, header=True)\n",
    "fcnm_data4, header4 = fits.getdata(fcnm_file_q3, header=True)\n",
    "#\n",
    "rhi_data1, header1 = fits.getdata(rhi_file_q0, header=True)\n",
    "rhi_data2, header2 = fits.getdata(rhi_file_q1, header=True)\n",
    "rhi_data3, header3 = fits.getdata(rhi_file_q2, header=True)\n",
    "rhi_data4, header4 = fits.getdata(rhi_file_q3, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbc0936f-1597-4b1b-bdc0-a4a36f54b79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n"
     ]
    }
   ],
   "source": [
    "print(cube1.shape)\n",
    "print(fcnm_data1.shape)\n",
    "print(rhi_data1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5a0733-e1fd-4ed7-938d-9bc1f851fbed",
   "metadata": {},
   "source": [
    "# test cnn_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f13313a2-f81a-4b8a-a3dc-d85ed58b6b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator-1\\Desktop\\New folder (6)\\DeepSpectra\\lib\\models\\learnable_PEV.pth\n"
     ]
    }
   ],
   "source": [
    "weights2 = model.learnable_PEV_ct_weights(device = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7241a1a3-c64a-4de4-8483-69cec34cdab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_tansformer = model.spectra_cnn_transformer(weights=weights2, num_output=2, PEV=\"trainable_PEV\",  drop_out_rate=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb64ec3d-5910-46ae-b666-d7f17a70f21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Fcnm, Rhi \u001b[38;5;241m=\u001b[39m \u001b[43mcalculator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcube\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcube3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcnn_tansformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPEV\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrainable_PEV\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\New folder (6)\\DeepSpectra\\lib\\predictor\\calculator.py:55\u001b[0m, in \u001b[0;36mcalculate\u001b[1;34m(cube, model, PEV)\u001b[0m\n\u001b[0;32m     53\u001b[0m position \u001b[38;5;241m=\u001b[39m o[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m#print('position=', position)\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspectra\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m Fcnm[position[\u001b[38;5;241m0\u001b[39m], position[\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m=\u001b[39mprediction[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     57\u001b[0m Rhi[position[\u001b[38;5;241m0\u001b[39m], position[\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m=\u001b[39mprediction[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Desktop\\New folder (6)\\DeepSpectra\\lib\\models\\prototype.py:212\u001b[0m, in \u001b[0;36mcnn_transformer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    210\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m9\u001b[39m)\n\u001b[0;32m    211\u001b[0m \u001b[38;5;66;03m# Transformer MODEL\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten(x)\n\u001b[0;32m    214\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(x)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:280\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[1;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[0;32m    277\u001b[0m         src_key_padding_mask_for_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 280\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[0;32m    283\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:538\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[1;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[0;32m    536\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 538\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    539\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:546\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[1;34m(self, x, attn_mask, key_padding_mask)\u001b[0m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sa_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor,\n\u001b[0;32m    545\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 546\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\activation.py:1167\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights)\u001b[0m\n\u001b[0;32m   1156\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[0;32m   1157\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[0;32m   1158\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1164\u001b[0m         q_proj_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_proj_weight, k_proj_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_proj_weight,\n\u001b[0;32m   1165\u001b[0m         v_proj_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj_weight, average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights)\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1167\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1169\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1170\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1171\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[0;32m   1176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:5156\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights)\u001b[0m\n\u001b[0;32m   5151\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   5152\u001b[0m \u001b[38;5;66;03m# (deep breath) calculate attention and out projection\u001b[39;00m\n\u001b[0;32m   5153\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   5155\u001b[0m B, Nt, E \u001b[38;5;241m=\u001b[39m q\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m-> 5156\u001b[0m q_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attn_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5158\u001b[0m     attn_output_weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbaddbmm(attn_mask, q_scaled, k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Fcnm, Rhi = calculator.calculate(cube = cube3, model=cnn_tansformer, PEV='trainable_PEV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cac70e-489a-4211-a401-18596e77887d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_(im, title, label):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(im, cmap='cividis')\n",
    "    cbar = plt.colorbar(shrink=0.5, pad=0.005)\n",
    "    cbar.set_label(f'${label}$', size=16)\n",
    "    plt.title(f'{title}')\n",
    "    plt.xlabel('X [Coordinate]')\n",
    "    plt.ylabel('Y [Coordinate]')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44a8aad-f859-4148-b463-6099ebd47c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_(Fcnm, 'Prediction_Fcnm', 'F_{cnm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11136ad5-8e51-4204-bfb7-18e1a053ceb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_(fcnm_data3, 'Ground_truth_Fcnm', 'F_{cnm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8702a9-81dc-40fb-bbde-9e1c23674f9b",
   "metadata": {},
   "source": [
    "# test cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed43bf6c-d16a-4711-bd54-172c7b739aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights1 = models.poly_concate_c_weights(device = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627765ac-9e42-4d22-afa5-9a4807b129a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.spectra_cnn(weights=weights1, num_output=2, in_channels=1, input_row = 2, input_column=101, drop_out_rate=0, lpe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142ad0b3-ad4e-4a80-959c-a1eb2caead85",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictt = dictionarizer.dict_maker(cube=cube3,Rhi=None, Fcnm=None).make_dict()\n",
    "print(len(dictt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991b2dbf-04f3-4262-b690-ad5efb9c9f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fcnm, Rhi = calculator.calculate(dictt = dictt, model=model, device='cpu', num_row=512, num_column=512, PEV='poly_concate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f14758-f90a-470f-815d-3144377ddd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_(im, title, label):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(im, cmap='cividis')\n",
    "    cbar = plt.colorbar(shrink=0.5, pad=0.005)\n",
    "    cbar.set_label(f'${label}$', size=16)\n",
    "    plt.title(f'{title}')\n",
    "    plt.xlabel('X [Coordinate]')\n",
    "    plt.ylabel('Y [Coordinate]')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ff039f-c111-462c-8312-375ad716230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_(Fcnm, 'Prediction_Fcnm', 'F_{cnm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3a285b-de2a-4ea0-bd09-952ebc5cc784",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_(fcnm_data3, 'Ground_truth_Fcnm', 'F_{cnm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0fe4c8-be26-4f63-9b2c-4ae41bc0dba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
